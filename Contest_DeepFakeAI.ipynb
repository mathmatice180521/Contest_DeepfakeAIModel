{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOn2tB3LzkcY9w/Q2yanqz/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ê¸° ìœ„í•œ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n","# ì‹œì‘í•  ë•Œ ë°˜ë“œì‹œ T4-GPU ì„¤ì •ìœ¼ë¡œ ëŒë¦¬ì„¸ìš”!\n","!pip install timm albumentations"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rI1r4bkrnMuX","executionInfo":{"status":"ok","timestamp":1767009881905,"user_tz":-540,"elapsed":13527,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"cbb2a889-114e-4894-c80d-f264fd64299f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.0.2)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.3)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.12.3)\n","Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.5.1)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.4)\n","Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"nKxn0Xxfm43Y","executionInfo":{"status":"ok","timestamp":1767010017170,"user_tz":-540,"elapsed":135263,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"2a222241-7551-467e-ea2d-1e981d14d278"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”» kaggle.json íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-798a4306-ab65-48d0-af2a-0c27715cda06\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-798a4306-ab65-48d0-af2a-0c27715cda06\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","ğŸ”» ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘... (ì•½ 2~3ë¶„ ì†Œìš”)\n","Dataset URL: https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces\n","License(s): other\n","Downloading 140k-real-and-fake-faces.zip to /content\n"," 99% 3.73G/3.75G [00:37<00:00, 297MB/s]\n","100% 3.75G/3.75G [00:37<00:00, 107MB/s]\n","âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! (./data í´ë” í™•ì¸)\n"]}],"source":["# [Cell 1] Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° í™˜ê²½ ì„¤ì •\n","import os\n","from google.colab import files\n","\n","# 1. kaggle.json ì—…ë¡œë“œ\n","if not os.path.exists('kaggle.json'):\n","    print(\"ğŸ”» kaggle.json íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n","    files.upload()\n","\n","# 2. Kaggle ì¸ì¦ ì„¤ì •\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# 3. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (140k-real-and-fake-faces)\n","# ì´ë¯¸ ì–¼êµ´ì´ ì˜ë ¤(Crop) ìˆì–´ì„œ ì „ì²˜ë¦¬ ì—†ì´ ë°”ë¡œ í•™ìŠµ ê°€ëŠ¥\n","if not os.path.exists('./data'):\n","    print(\"ğŸ”» ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘... (ì•½ 2~3ë¶„ ì†Œìš”)\")\n","    !kaggle datasets download -d xhlulu/140k-real-and-fake-faces\n","    !unzip -q 140k-real-and-fake-faces.zip -d ./data\n","    print(\"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! (./data í´ë” í™•ì¸)\")\n","else:\n","    print(\"âœ… ì´ë¯¸ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\")"]},{"cell_type":"code","source":["# [Cell 2] í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„±\n","import os\n","\n","folders = ['model', 'src', 'config', 'train_data', 'test_data']\n","for folder in folders:\n","    os.makedirs(folder, exist_ok=True)\n","\n","print(\"âœ… í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ: model/, src/, config/ ë“±\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JtXvaJIm8ZN","executionInfo":{"status":"ok","timestamp":1767010044640,"user_tz":-540,"elapsed":48,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"61fadaa7-d47e-4716-f200-19859c27917a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ: model/, src/, config/ ë“±\n"]}]},{"cell_type":"code","source":["%%writefile config/config.yaml\n","# [Config] ì‹¤í—˜ ì„¤ì • íŒŒì¼\n","SEED: 42\n","IMG_SIZE: 224        # EfficientNet-B4ë¼ë©´ 380 ê¶Œì¥, ë¹ ë¥¸ ì‹¤í—˜ ìœ„í•´ 224 ì„¤ì •\n","BATCH_SIZE: 32\n","EPOCHS: 10\n","LEARNING_RATE: 0.0001\n","MODEL_NAME: 'tf_efficientnet_b4_ns' # ì¶”ì²œ ëª¨ë¸\n","DATA_PATH: './data/real_vs_fake/real-vs-fake' # Kaggle ë°ì´í„° ê²½ë¡œ\n","SAVE_PATH: './model/best_model.pt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RG6hvvI8m_Km","executionInfo":{"status":"ok","timestamp":1767010053379,"user_tz":-540,"elapsed":4,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"2c87424a-257a-48c4-b699-031899feefb0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing config/config.yaml\n"]}]},{"cell_type":"code","source":["%%writefile src/dataset.py\n","import cv2\n","import torch\n","import numpy as np\n","from torch.utils.data import Dataset\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","class DeepfakeDataset(Dataset):\n","    def __init__(self, file_paths, labels=None, transform=None):\n","        self.file_paths = file_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        path = self.file_paths[idx]\n","        image = cv2.imread(path)\n","\n","        # ì˜ˆì™¸ì²˜ë¦¬: ì´ë¯¸ì§€ê°€ ì•ˆ ì½í ê²½ìš° ê²€ì€ í™”ë©´ ë°˜í™˜\n","        if image is None:\n","            image = np.zeros((224, 224, 3), dtype=np.uint8)\n","        else:\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.transform:\n","            augmented = self.transform(image=image)\n","            image = augmented['image']\n","\n","        if self.labels is not None:\n","            return image, torch.tensor(self.labels[idx], dtype=torch.float32)\n","        else:\n","            return image\n","\n","def get_transforms(img_size):\n","    # í•™ìŠµìš© ì¦ê°•\n","    train_aug = A.Compose([\n","        A.Resize(img_size, img_size),\n","        A.HorizontalFlip(p=0.5),\n","        A.GaussNoise(p=0.2), # ë…¸ì´ì¦ˆ ì¶”ê°€ (í™”ì§ˆêµ¬ì§€ ëŒ€ì‘)\n","        A.Normalize(),\n","        ToTensorV2()\n","    ])\n","    # ê²€ì¦/ì¶”ë¡ ìš© (ì¦ê°• ì—†ìŒ)\n","    valid_aug = A.Compose([\n","        A.Resize(img_size, img_size),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ])\n","    return train_aug, valid_aug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Rp3NYDmnAdT","executionInfo":{"status":"ok","timestamp":1767010054796,"user_tz":-540,"elapsed":5,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"2383b739-35b6-48c7-9581-b4eaeb23f0a5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing src/dataset.py\n"]}]},{"cell_type":"code","source":["%%writefile src/models.py\n","import torch.nn as nn\n","import timm\n","\n","class DeepfakeModel(nn.Module):\n","    def __init__(self, model_name, pretrained=True):\n","        super(DeepfakeModel, self).__init__()\n","        # 1. ëª¨ë¸ ë¡œë“œ (pretrained=Falseë©´ ê»ë°ê¸°ë§Œ ë¡œë“œë¨)\n","        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=1)\n","\n","    def forward(self, x):\n","        return self.model(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYcwSN6RnCw7","executionInfo":{"status":"ok","timestamp":1767010056635,"user_tz":-540,"elapsed":6,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"d598634b-0786-4e1d-b2c0-2cc1950f8f78"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing src/models.py\n"]}]},{"cell_type":"code","source":["%%writefile train.py\n","import os\n","import glob\n","import yaml\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from tqdm.auto import tqdm\n","\n","# ìœ„ì—ì„œ ë§Œë“  ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°\n","from src.dataset import DeepfakeDataset, get_transforms\n","from src.models import DeepfakeModel\n","\n","# Config ë¡œë“œ\n","with open('config/config.yaml') as f:\n","    CFG = yaml.safe_load(f)\n","\n","def train():\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f\"Using Device: {device}\")\n","\n","    # 1. ë°ì´í„° ë¡œë“œ (Kaggle ë°ì´í„° êµ¬ì¡°ì— ë§ì¶¤)\n","    print(\"Load Data...\")\n","    base_path = CFG['DATA_PATH']\n","\n","    # Real: 0, Fake: 1\n","    real_paths = glob.glob(os.path.join(base_path, 'train/real/*.jpg'))\n","    fake_paths = glob.glob(os.path.join(base_path, 'train/fake/*.jpg'))\n","\n","    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë°ì´í„° ì¼ë¶€ë§Œ ì‚¬ìš© (í•„ìš”ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ ì „ì²´ ì‚¬ìš©)\n","    # real_paths = real_paths[:1000]\n","    # fake_paths = fake_paths[:1000]\n","\n","    all_paths = real_paths + fake_paths\n","    labels = [0]*len(real_paths) + [1]*len(fake_paths)\n","\n","    # Train/Valid Split\n","    train_paths, val_paths, train_labels, val_labels = train_test_split(\n","        all_paths, labels, test_size=0.2, random_state=CFG['SEED'], stratify=labels\n","    )\n","\n","    # Transforms\n","    train_tf, valid_tf = get_transforms(CFG['IMG_SIZE'])\n","\n","    # DataLoader\n","    train_loader = DataLoader(\n","        DeepfakeDataset(train_paths, train_labels, train_tf),\n","        batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=2\n","    )\n","    val_loader = DataLoader(\n","        DeepfakeDataset(val_paths, val_labels, valid_tf),\n","        batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=2\n","    )\n","\n","    # 2. ëª¨ë¸ ì¤€ë¹„\n","    model = DeepfakeModel(CFG['MODEL_NAME'], pretrained=True).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    best_loss = float('inf')\n","\n","    # 3. í•™ìŠµ ë£¨í”„\n","    print(\"Start Training...\")\n","    for epoch in range(1, CFG['EPOCHS'] + 1):\n","        model.train()\n","        train_loss = 0\n","\n","        for imgs, targets in tqdm(train_loader, desc=f\"Epoch {epoch} Train\"):\n","            imgs, targets = imgs.to(device), targets.to(device).unsqueeze(1)\n","\n","            optimizer.zero_grad()\n","            outputs = model(imgs)\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","\n","        # ê²€ì¦\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for imgs, targets in val_loader:\n","                imgs, targets = imgs.to(device), targets.to(device).unsqueeze(1)\n","                outputs = model(imgs)\n","                loss = criterion(outputs, targets)\n","                val_loss += loss.item()\n","\n","        train_loss /= len(train_loader)\n","        val_loss /= len(val_loader)\n","\n","        print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n","\n","        # ëª¨ë¸ ì €ì¥ (Loss ê¸°ì¤€)\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            torch.save(model.state_dict(), CFG['SAVE_PATH'])\n","            print(f\"âœ… Best Model Saved! ({val_loss:.4f})\")\n","\n","if __name__ == '__main__':\n","    train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTSrz6oAnEHB","executionInfo":{"status":"ok","timestamp":1767010057847,"user_tz":-540,"elapsed":7,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"0743635f-9282-49ac-bf9d-0924c7d5f118"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing train.py\n"]}]},{"cell_type":"code","source":["!python train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zbx96dEw_jI5","executionInfo":{"status":"ok","timestamp":1767013776577,"user_tz":-540,"elapsed":3716217,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"3fa3b206-6de7-4cc4-d30e-4bacfc612cd9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using Device: cuda\n","Load Data...\n","/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n","  model = create_fn(\n","model.safetensors: 100% 77.9M/77.9M [00:01<00:00, 60.9MB/s]\n","Start Training...\n","Epoch 1 Train: 100% 2500/2500 [19:04<00:00,  2.19it/s]\n","Epoch 1 | Train Loss: 0.2768 | Val Loss: 0.0401\n","âœ… Best Model Saved! (0.0401)\n","Epoch 2 Train: 100% 2500/2500 [19:13<00:00,  2.17it/s]\n","Epoch 2 | Train Loss: 0.0961 | Val Loss: 0.0263\n","âœ… Best Model Saved! (0.0263)\n","Epoch 3 Train: 100% 2500/2500 [19:12<00:00,  2.17it/s]\n","Epoch 3 | Train Loss: 0.0732 | Val Loss: 0.0112\n","âœ… Best Model Saved! (0.0112)\n","Epoch 4 Train:   0% 7/2500 [00:04<23:54,  1.74it/s]\n","Traceback (most recent call last):\n","  File \"/content/train.py\", line 101, in <module>\n","    train()\n","  File \"/content/train.py\", line 77, in train\n","    train_loss += loss.item()\n","                  ^^^^^^^^^^^\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["# [Cell] êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ ë° ì§€ì •ëœ 6ê°œ í™•ì¥ì íŒŒì¼ ì¶”ì¶œ\n","import os\n","import shutil\n","import glob\n","from google.colab import drive\n","\n","# 1. ê¸°ì¡´ í´ë” ì •ë¦¬ (ê¹¨ë—í•˜ê²Œ ì´ˆê¸°í™”)\n","if os.path.exists('./test_data'):\n","    shutil.rmtree('./test_data')\n","if os.path.exists('./temp_test'):\n","    shutil.rmtree('./temp_test')\n","\n","# 2. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n","drive.mount('/content/drive')\n","\n","# 3. ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ìë‹˜ ë“œë¼ì´ë¸Œ ê²½ë¡œ)\n","drive_path = '/content/drive/MyDrive/ë”¥í˜ì´í¬ AI ëŒ€íšŒ/test.zip'\n","\n","if os.path.exists(drive_path):\n","    print(f\"âœ… êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤! ({os.path.getsize(drive_path)/1024/1024:.2f} MB)\")\n","\n","    # ì••ì¶• í’€ê¸°\n","    print(\"ğŸ“¦ ì••ì¶• í•´ì œ ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)\")\n","    !unzip -q \"{drive_path}\" -d ./temp_test\n","\n","    # 4. íŒŒì¼ ì´ë™ (ì§€ì •í•´ì£¼ì‹  6ê°œ í™•ì¥ìë§Œ íƒ€ê²ŸíŒ…)\n","    os.makedirs('./test_data', exist_ok=True)\n","\n","    # ê²€ìƒ‰í•  í™•ì¥ì ë¦¬ìŠ¤íŠ¸ (ëŒ€ì†Œë¬¸ì ëª¨ë‘ í¬í•¨í•˜ë„ë¡ ì„¤ì •)\n","    target_extensions = ['jfif', 'jpeg', 'jpg', 'mov', 'mp4', 'png']\n","    search_patterns = []\n","\n","    # ì˜ˆ: *.jpg ì™€ *.JPG ë¥¼ ëª¨ë‘ ê²€ìƒ‰ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n","    for ext in target_extensions:\n","        search_patterns.append(f'*.{ext.lower()}')\n","        search_patterns.append(f'*.{ext.upper()}')\n","\n","    print(f\"ê²€ìƒ‰í•  í™•ì¥ìë“¤: {search_patterns}\")\n","\n","    all_files = []\n","    for pattern in search_patterns:\n","        # ì¬ê·€ì ìœ¼ë¡œ í´ë” ê¹Šìˆ™í•œ ê³³ê¹Œì§€ ê²€ìƒ‰\n","        found = glob.glob(f'./temp_test/**/{pattern}', recursive=True)\n","        all_files.extend(found)\n","\n","    print(f\"ì´ {len(all_files)}ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë™ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n","\n","    # íŒŒì¼ ì´ë™ ì‹¤í–‰\n","    for file in all_files:\n","        try:\n","            # íŒŒì¼ëª…ì´ ê²¹ì¹  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë®ì–´ì“°ê¸° í˜¹ì€ ê±´ë„ˆë›°ê¸°\n","            shutil.move(file, './test_data')\n","        except shutil.Error:\n","            print(f\"âš ï¸ ì¤‘ë³µ íŒŒì¼ ì¡´ì¬: {os.path.basename(file)} (ê±´ë„ˆëœ€)\")\n","        except Exception as e:\n","            print(f\"âŒ ì´ë™ ì‹¤íŒ¨: {file} - {e}\")\n","\n","    # ìµœì¢… í™•ì¸\n","    final_count = len(os.listdir('./test_data'))\n","    print(f\"ğŸ‰ ì„±ê³µ! ./test_data í´ë” ì•ˆì— ì´ {final_count}ê°œì˜ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","    # ì„ì‹œ í´ë” ì‚­ì œ\n","    shutil.rmtree('./temp_test')\n","\n","else:\n","    print(f\"âŒ '{drive_path}' ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n","    print(\"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê²½ë¡œì™€ íŒŒì¼ëª…ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT63I8_NPp7N","executionInfo":{"status":"ok","timestamp":1767014756612,"user_tz":-540,"elapsed":21373,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"318361a4-ac80-467f-96c3-b1dcc749e80e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","âœ… êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤! (1808.57 MB)\n","ğŸ“¦ ì••ì¶• í•´ì œ ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)\n","ê²€ìƒ‰í•  í™•ì¥ìë“¤: ['*.jfif', '*.JFIF', '*.jpeg', '*.JPEG', '*.jpg', '*.JPG', '*.mov', '*.MOV', '*.mp4', '*.MP4', '*.png', '*.PNG']\n","ì´ 500ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë™ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n","ğŸ‰ ì„±ê³µ! ./test_data í´ë” ì•ˆì— ì´ 500ê°œì˜ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"]}]},{"cell_type":"code","source":["# ì–¼êµ´ë§Œ ì˜¤ë ¤ë‚´ëŠ” ê°€ìœ„ë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´ ì¶”ê°€ì ì¸ pipë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n","!pip install facenet-pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"N3lEfXLJaURU","executionInfo":{"status":"ok","timestamp":1767017065476,"user_tz":-540,"elapsed":202257,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"d8cc2681-846b-4c50-f943-a6af7c7ed96e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n","Collecting numpy<2.0.0,>=1.24.0 (from facenet-pytorch)\n","  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n","  Downloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (2.32.4)\n","Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch)\n","  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n","Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch)\n","  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (4.67.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.11.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.6.85)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n","Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet-pytorch\n","  Attempting uninstall: Pillow\n","    Found existing installation: pillow 11.3.0\n","    Uninstalling pillow-11.3.0:\n","      Successfully uninstalled pillow-11.3.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.5\n","    Uninstalling nvidia-nccl-cu12-2.27.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n","    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.9.0+cu126\n","    Uninstalling torch-2.9.0+cu126:\n","      Successfully uninstalled torch-2.9.0+cu126\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.24.0+cu126\n","    Uninstalling torchvision-0.24.0+cu126:\n","      Successfully uninstalled torchvision-0.24.0+cu126\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Pillow-10.2.0 facenet-pytorch-2.6.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"00eb7464af6c46e296111f48bc031284"}},"metadata":{}}]},{"cell_type":"code","source":["%%writefile inference.py\n","import os\n","import cv2\n","import yaml\n","import torch\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from facenet_pytorch import MTCNN\n","from src.dataset import DeepfakeDataset, get_transforms\n","from src.models import DeepfakeModel\n","\n","def inference(test_dir, model_path, output_path):\n","    # --- ì„¤ì • ---\n","    with open('config/config.yaml') as f:\n","        CFG = yaml.safe_load(f)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # --- ëª¨ë¸ ë¡œë“œ ---\n","    model = DeepfakeModel(CFG['MODEL_NAME'], pretrained=False)\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.to(device)\n","    model.eval()\n","\n","    # --- ì–¼êµ´ íƒì§€ê¸° ì„¤ì • (Kaggle ë°ì´í„°ì²˜ëŸ¼ íƒ€ì´íŠ¸í•˜ê²Œ) ---\n","    # margin=0 : ì–¼êµ´ì„ íƒ€ì´íŠ¸í•˜ê²Œ ìë¦„\n","    # select_largest=True : í™”ë©´ì—ì„œ ì œì¼ í° ì–¼êµ´ í•˜ë‚˜ë§Œ ê°€ì ¸ì˜´\n","    mtcnn = MTCNN(keep_all=False, select_largest=True, device=device, margin=0)\n","\n","    # Transforms\n","    _, valid_tf = get_transforms(CFG['IMG_SIZE'])\n","\n","    # --- íŒŒì¼ ëª©ë¡ ---\n","    VALID_EXTENSIONS = ('.mp4', '.mov', '.avi', '.jpg', '.jpeg', '.png', '.jfif')\n","    file_paths = []\n","    for f in os.listdir(test_dir):\n","        if f.lower().endswith(VALID_EXTENSIONS):\n","            file_paths.append(os.path.join(test_dir, f))\n","\n","    print(f\"âœ… Inference Start! íŒŒì¼: {len(file_paths)}ê°œ\")\n","\n","    # [ë””ë²„ê¹…ìš©] AIê°€ ë³´ëŠ” ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë” ìƒì„±\n","    os.makedirs('./debug_images', exist_ok=True)\n","    saved_debug_count = 0\n","\n","    results = []\n","\n","    for path in tqdm(file_paths):\n","        filename = os.path.basename(path)\n","        ext = filename.split('.')[-1].lower()\n","\n","        frames = []\n","\n","        # --- ì†ŒìŠ¤ ì½ê¸° ---\n","        if ext in ['mp4', 'mov', 'avi']:\n","            cap = cv2.VideoCapture(path)\n","            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","            # ì˜ìƒì€ ì¤‘ì•™ í”„ë ˆì„ ìœ„ì£¼ë¡œ 5ì¥ë§Œ ë½‘ì•„ì„œ ë¹ ë¥´ê²Œ (ì†ë„ ê°œì„ )\n","            if frame_count > 10:\n","                intervals = np.linspace(frame_count//4, frame_count*3//4, 5, dtype=int)\n","            else:\n","                intervals = [0]\n","\n","            raw_frames = []\n","            for idx in intervals:\n","                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n","                ret, frame = cap.read()\n","                if ret:\n","                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","                    raw_frames.append(frame)\n","            cap.release()\n","        else:\n","            image = cv2.imread(path)\n","            if image is not None:\n","                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","                raw_frames = [image]\n","            else:\n","                raw_frames = []\n","\n","        # --- ì–¼êµ´ ì¶”ì¶œ ë° ì „ì²˜ë¦¬ ---\n","        for i, frame in enumerate(raw_frames):\n","            # 1. ì–¼êµ´ íƒì§€\n","            boxes, _ = mtcnn.detect(frame)\n","\n","            face_img = None\n","            if boxes is not None:\n","                # ì–¼êµ´ ì°¾ìŒ -> ìë¥´ê¸°\n","                x1, y1, x2, y2 = [int(b) for b in boxes[0]]\n","                # ì¢Œí‘œ ë³´ì •\n","                x1, y1 = max(0, x1), max(0, y1)\n","                x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n","\n","                # ì–¼êµ´ ì˜ì—­ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ë¬´ì‹œ (ë…¸ì´ì¦ˆì¼ ìˆ˜ ìˆìŒ)\n","                if (x2-x1) > 30 and (y2-y1) > 30:\n","                    face_img = frame[y1:y2, x1:x2]\n","\n","            # ì–¼êµ´ ëª» ì°¾ì•˜ìœ¼ë©´? -> ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë³´í—˜)\n","            if face_img is None:\n","                face_img = frame\n","\n","            # 2. Augmentation (Resize & Normalize)\n","            augmented = valid_tf(image=face_img)\n","            input_tensor = augmented['image']\n","            frames.append(input_tensor)\n","\n","            # [ë””ë²„ê¹…] ì²˜ìŒ 10ê°œ ì´ë¯¸ì§€ë§Œ ì €ì¥í•´ì„œ ëˆˆìœ¼ë¡œ í™•ì¸\n","            if saved_debug_count < 10:\n","                # ì •ê·œí™”ëœ í…ì„œë¥¼ ë‹¤ì‹œ ì´ë¯¸ì§€ë¡œ ë³µêµ¬í•´ì„œ ì €ì¥\n","                debug_img = input_tensor.permute(1, 2, 0).cpu().numpy()\n","                # Normalize ë³µêµ¬ (ëŒ€ëµì )\n","                debug_img = (debug_img * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n","                debug_img = np.clip(debug_img * 255, 0, 255).astype(np.uint8)\n","                debug_img = cv2.cvtColor(debug_img, cv2.COLOR_RGB2BGR)\n","                cv2.imwrite(f'./debug_images/debug_{filename}_{i}.jpg', debug_img)\n","                saved_debug_count += 1\n","\n","        if len(frames) == 0:\n","            results.append({'filename': filename, 'prob': 0.5})\n","            continue\n","\n","        # --- ì¶”ë¡  ---\n","        frames = torch.stack(frames).to(device)\n","        with torch.no_grad():\n","            outputs = model(frames)\n","            probs = torch.sigmoid(outputs)\n","\n","        avg_prob = probs.mean().item()\n","        results.append({'filename': filename, 'prob': avg_prob})\n","\n","    # ê²°ê³¼ ì €ì¥\n","    submission = pd.DataFrame(results)\n","    submission.to_csv(output_path, index=False)\n","\n","    print(f\"âœ… Submission Saved: {output_path}\")\n","    print(\"ğŸ” ì˜ˆì¸¡ê°’ í†µê³„ (0.5ì— ëª°ë ¤ìˆìœ¼ë©´ í•™ìŠµ/ì¶”ë¡  ë¶ˆì¼ì¹˜):\")\n","    print(submission['prob'].describe())\n","\n","if __name__ == '__main__':\n","    TEST_DIR = './test_data'\n","    MODEL_PATH = './model/best_model.pt'\n","    OUTPUT_PATH = './submission.csv'\n","\n","    if os.path.exists(TEST_DIR) and os.path.exists(MODEL_PATH):\n","        inference(TEST_DIR, MODEL_PATH, OUTPUT_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfLUSle1nFuG","executionInfo":{"status":"ok","timestamp":1767018763506,"user_tz":-540,"elapsed":10,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"749e2bad-7bf2-4967-d741-52d91ee80d29"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting inference.py\n"]}]},{"cell_type":"code","source":["!python inference.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmkT_KmfBuwX","executionInfo":{"status":"ok","timestamp":1767019387958,"user_tz":-540,"elapsed":622489,"user":{"displayName":"ê¹€ë¯¼ì„±","userId":"02277606854389441221"}},"outputId":"56af7d38-e161-4640-b0e9-d7ac3171f470"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n","  model = create_fn(\n","âœ… Inference Start! íŒŒì¼: 500ê°œ\n","100% 500/500 [10:13<00:00,  1.23s/it]\n","âœ… Submission Saved: ./submission.csv\n","ğŸ” ì˜ˆì¸¡ê°’ í†µê³„ (0.5ì— ëª°ë ¤ìˆìœ¼ë©´ í•™ìŠµ/ì¶”ë¡  ë¶ˆì¼ì¹˜):\n","count    5.000000e+02\n","mean     9.479996e-04\n","std      7.688760e-03\n","min      0.000000e+00\n","25%      5.155419e-18\n","50%      1.963089e-10\n","75%      3.654069e-06\n","max      1.186678e-01\n","Name: prob, dtype: float64\n"]}]}]}